{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keyboard\n",
      "  Downloading keyboard-0.13.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Downloading keyboard-0.13.5-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: keyboard\n",
      "Successfully installed keyboard-0.13.5\n"
     ]
    }
   ],
   "source": [
    "# !pip install pytesseract\n",
    "!pip install keyboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4 (listen_for_stop_key):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/manish/Desktop/testGUI/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_4442/2934389245.py\", line 114, in listen_for_stop_key\n",
      "  File \"/home/manish/Desktop/testGUI/.venv/lib/python3.12/site-packages/keyboard/__init__.py\", line 881, in wait\n",
      "    remove = add_hotkey(hotkey, lambda: lock.set(), suppress=suppress, trigger_on_release=trigger_on_release)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/manish/Desktop/testGUI/.venv/lib/python3.12/site-packages/keyboard/__init__.py\", line 639, in add_hotkey\n",
      "    _listener.start_if_necessary()\n",
      "  File \"/home/manish/Desktop/testGUI/.venv/lib/python3.12/site-packages/keyboard/_generic.py\", line 35, in start_if_necessary\n",
      "    self.init()\n",
      "  File \"/home/manish/Desktop/testGUI/.venv/lib/python3.12/site-packages/keyboard/__init__.py\", line 196, in init\n",
      "    _os_keyboard.init()\n",
      "  File \"/home/manish/Desktop/testGUI/.venv/lib/python3.12/site-packages/keyboard/_nixkeyboard.py\", line 113, in init\n",
      "    build_device()\n",
      "  File \"/home/manish/Desktop/testGUI/.venv/lib/python3.12/site-packages/keyboard/_nixkeyboard.py\", line 109, in build_device\n",
      "    ensure_root()\n",
      "  File \"/home/manish/Desktop/testGUI/.venv/lib/python3.12/site-packages/keyboard/_nixcommon.py\", line 174, in ensure_root\n",
      "    raise ImportError('You must be root to use this library on linux.')\n",
      "ImportError: You must be root to use this library on linux.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¥ Press Ctrl+Shift+X at any time to stop the script.\n",
      "OpenCV is installed - using enhanced image recognition\n",
      "Found saved search bar position: (1140.0, 130.0)\n",
      " Loaded 1308 search terms from labTestName.csv\n",
      "Starting in 5 seconds. Switch to Discord now!\n",
      "5...\n",
      "4...\n",
      "3...\n",
      "2...\n",
      "1...\n",
      "\n",
      "[Search 1/1308] Term: '17- KETOSTEROIDS'\n",
      "Clicking search bar at saved position 1140.0, 130.0\n",
      "Clearing search field\n",
      "Typing search term: 17- KETOSTEROIDS\n",
      "Pressing Enter to search\n",
      "Waiting 3.0 seconds before next search...\n",
      "\n",
      "[Search 2/1308] Term: '24 HOUR URINE FOR AMYLASE'\n",
      "Clicking search bar at saved position 1140.0, 130.0\n",
      "Clearing search field\n",
      "Typing search term: 24 HOUR URINE FOR AMYLASE\n",
      "Pressing Enter to search\n",
      "Waiting 3.0 seconds before next search...\n",
      "\n",
      "[Search 3/1308] Term: '24 HOUR URINE FOR PROTEIN'\n",
      "Clicking search bar at saved position 1140.0, 130.0\n",
      "Clearing search field\n",
      "Typing search term: 24 HOUR URINE FOR PROTEIN\n",
      "\n",
      "‚ö†Ô∏è Script terminated by user\n"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import threading\n",
    "import keyboard  # for hotkey detection\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "def locate_search_bar_once(template_path):\n",
    "    print(f\"Looking for search bar using template: {template_path}\")\n",
    "    \n",
    "    try:\n",
    "        for confidence in [0.9, 0.8, 0.7]:\n",
    "            try:\n",
    "                print(f\"Trying with confidence level: {confidence}\")\n",
    "                location = pyautogui.locateOnScreen(template_path, confidence=confidence)\n",
    "                if location:\n",
    "                    x, y = pyautogui.center(location)\n",
    "                    print(f\" Found search bar at position: {x}, {y}\")\n",
    "                    return (x, y)\n",
    "            except Exception as e:\n",
    "                if \"confidence\" in str(e):\n",
    "                    print(\"OpenCV required for confidence parameter.\")\n",
    "                    print(\"Attempting without confidence parameter...\")\n",
    "                    location = pyautogui.locateOnScreen(template_path)\n",
    "                    if location:\n",
    "                        x, y = pyautogui.center(location)\n",
    "                        print(f\" Found search bar at position: {x}, {y}\")\n",
    "                        return (x, y)\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"Error: {e}\")\n",
    "        \n",
    "        print(\" Search bar not found on screen\")\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error locating search bar: {e}\")\n",
    "        return None\n",
    "\n",
    "def perform_discord_searches_with_saved_position(search_bar_pos, search_terms):\n",
    "    x, y = search_bar_pos\n",
    "    \n",
    "    for idx, term in enumerate(search_terms):\n",
    "        try:\n",
    "            print(f\"\\n[Search {idx+1}/{len(search_terms)}] Term: '{term}'\")\n",
    "            print(f\"Clicking search bar at saved position {x}, {y}\")\n",
    "            pyautogui.moveTo(x, y, duration=0.5)\n",
    "            pyautogui.click()\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "            print(\"Clearing search field\")\n",
    "            pyautogui.hotkey('ctrl', 'a')\n",
    "            time.sleep(0.2)\n",
    "            pyautogui.hotkey('backspace')\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "            print(f\"Typing search term: {term}\")\n",
    "            pyautogui.write(term, interval=0.1)\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "            print(\"Pressing Enter to search\")\n",
    "            pyautogui.press('enter')\n",
    "            \n",
    "            wait_time = 3.0\n",
    "            print(f\"Waiting {wait_time:.1f} seconds before next search...\")\n",
    "            time.sleep(wait_time)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during search operation: {e}\")\n",
    "    \n",
    "    print(\"\\nAll search operations completed!\")\n",
    "\n",
    "def save_search_bar_position(position):\n",
    "    try:\n",
    "        with open(\"search_bar_position.txt\", \"w\") as f:\n",
    "            f.write(f\"{position[0]},{position[1]}\")\n",
    "        print(f\" Search bar position saved to search_bar_position.txt\")\n",
    "    except Exception as e:\n",
    "        print(f\" Failed to save search bar position: {e}\")\n",
    "\n",
    "def load_search_bar_position():\n",
    "    try:\n",
    "        if os.path.exists(\"search_bar_position.txt\"):\n",
    "            with open(\"search_bar_position.txt\", \"r\") as f:\n",
    "                x, y = f.read().strip().split(\",\")\n",
    "                return (float(x), float(y))\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\" Failed to load search bar position: {e}\")\n",
    "        return None\n",
    "\n",
    "def reset_saved_position():\n",
    "    if os.path.exists(\"search_bar_position.txt\"):\n",
    "        os.remove(\"search_bar_position.txt\")\n",
    "        print(\" Saved position has been reset. Will search for search bar on next run.\")\n",
    "\n",
    "def load_search_terms_from_csv(csv_path):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if 'TESTNAME' not in df.columns:\n",
    "            print(f\" 'TESTNAME' column not found in {csv_path}\")\n",
    "            return []\n",
    "        terms = df['TESTNAME'].dropna().astype(str).str.strip().tolist()\n",
    "        print(f\" Loaded {len(terms)} search terms from {csv_path}\")\n",
    "        return terms\n",
    "    except Exception as e:\n",
    "        print(f\" Failed to load search terms: {e}\")\n",
    "        return []\n",
    "\n",
    "def listen_for_stop_key():\n",
    "    print(\"üî¥ Press Ctrl+Shift+X at any time to stop the script.\")\n",
    "    keyboard.wait('ctrl+shift+x')\n",
    "    print(\"\\nüõë Ctrl+Shift+X pressed. Exiting...\")\n",
    "    os._exit(0)  # Force immediate exit\n",
    "\n",
    "def main():\n",
    "    saved_position = load_search_bar_position()\n",
    "    \n",
    "    if saved_position:\n",
    "        print(f\"Found saved search bar position: {saved_position}\")\n",
    "        search_bar_pos = saved_position\n",
    "    else:\n",
    "        template_path = \"image_copy.png\"\n",
    "        \n",
    "        if not os.path.exists(template_path):\n",
    "            print(f\" Template image not found at: {template_path}\")\n",
    "            print(\"Please create a screenshot of the Discord search bar and save it as:\")\n",
    "            print(f\"  {os.path.abspath(template_path)}\")\n",
    "            return\n",
    "            \n",
    "        search_bar_pos = locate_search_bar_once(template_path)\n",
    "        \n",
    "        if not search_bar_pos:\n",
    "            print(\" Could not locate search bar. Exiting.\")\n",
    "            return\n",
    "            \n",
    "        save_search_bar_position(search_bar_pos)\n",
    "    \n",
    "    csv_path = \"labTestName.csv\"\n",
    "    search_terms = load_search_terms_from_csv(csv_path)\n",
    "\n",
    "    if not search_terms:\n",
    "        print(\" No search terms loaded. Make sure the CSV file and 'TESTNAME' column exist.\")\n",
    "        return\n",
    "\n",
    "    print(\"Starting in 5 seconds. Switch to Discord now!\")\n",
    "    for i in range(5, 0, -1):\n",
    "        print(f\"{i}...\")\n",
    "        time.sleep(1)\n",
    "    \n",
    "    perform_discord_searches_with_saved_position(search_bar_pos, search_terms)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        threading.Thread(target=listen_for_stop_key, daemon=True).start()\n",
    "\n",
    "        if len(sys.argv) > 1 and sys.argv[1] == \"--reset\":\n",
    "            reset_saved_position()\n",
    "            sys.exit(0)\n",
    "        \n",
    "        try:\n",
    "            import cv2\n",
    "            print(\"OpenCV is installed - using enhanced image recognition\")\n",
    "        except ImportError:\n",
    "            print(\"‚ö†Ô∏è OpenCV not found. For better results, install opencv-python:\")\n",
    "            print(\"pip install opencv-python\")\n",
    "        \n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚ö†Ô∏è Script terminated by user\")\n",
    "    except Exception as e:\n",
    "        print(f\" An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image 'HELLO.png' has 13 rows.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def count_rows(image_path):\n",
    "    # Read the image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Could not read image: {image_path}\")\n",
    "        return 0\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                  cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    # Detect horizontal lines\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 1))\n",
    "    detected_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)\n",
    "    \n",
    "    # Find contours of the lines\n",
    "    cnts = cv2.findContours(detected_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    \n",
    "    # Filter out small lines (noise)\n",
    "    min_line_length = img.shape[1] * 0.5  # At least 50% of image width\n",
    "    lines = []\n",
    "    for c in cnts:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        if w > min_line_length:\n",
    "            lines.append(y + h // 2)  # Store the y-coordinate of the line center\n",
    "    \n",
    "    # Sort the lines and count unique rows\n",
    "    if not lines:\n",
    "        # If no lines detected, try text-based approach\n",
    "        return count_rows_by_text(img)\n",
    "    \n",
    "    lines.sort()\n",
    "    \n",
    "    # Group nearby lines (within threshold) as part of the same row separator\n",
    "    row_separators = []\n",
    "    threshold = 20  # pixels\n",
    "    prev_y = None\n",
    "    \n",
    "    for y in lines:\n",
    "        if prev_y is None or abs(y - prev_y) > threshold:\n",
    "            row_separators.append(y)\n",
    "            prev_y = y\n",
    "    \n",
    "    # Number of rows is number of separators + 1\n",
    "    return len(row_separators) + 1\n",
    "\n",
    "def count_rows_by_text(img):\n",
    "    # Alternative method based on text block detection\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    \n",
    "    # Detect text blocks\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 5))\n",
    "    dilate = cv2.dilate(thresh, kernel, iterations=4)\n",
    "    \n",
    "    cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    \n",
    "    # Get y-coordinates of text blocks\n",
    "    text_blocks = []\n",
    "    for c in cnts:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        text_blocks.append(y)\n",
    "    \n",
    "    if not text_blocks:\n",
    "        return 1  # Default to 1 row if no text detected\n",
    "    \n",
    "    # Cluster y-coordinates to determine rows\n",
    "    text_blocks = sorted(text_blocks)\n",
    "    clusters = []\n",
    "    threshold = 30  # pixels\n",
    "    \n",
    "    current_cluster = [text_blocks[0]]\n",
    "    for y in text_blocks[1:]:\n",
    "        if y - current_cluster[-1] <= threshold:\n",
    "            current_cluster.append(y)\n",
    "        else:\n",
    "            clusters.append(current_cluster)\n",
    "            current_cluster = [y]\n",
    "    clusters.append(current_cluster)\n",
    "    \n",
    "    return len(clusters)\n",
    "\n",
    "# Test with a single image\n",
    "image_path = 'HELLO.png'\n",
    "row_count = count_rows(image_path)\n",
    "print(f\"The image '{image_path}' has {row_count} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "\n",
    "# Take screenshot\n",
    "screenshot = pyautogui.screenshot()\n",
    "\n",
    "# Save to file\n",
    "screenshot.save(\"screenshot.png\")  # Saves in the current directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**High Contrast**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved high contrast image as 'high_contrast_image.png'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load grayscale image\n",
    "gray = cv2.imread(\"image3.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply histogram equalization\n",
    "equalized = cv2.equalizeHist(gray)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"high_contrast_image.png\", equalized)\n",
    "\n",
    "print(\"Saved high contrast image as 'high_contrast_image.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 2 very big rows (line length ‚â• 500).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def count_very_long_rows(image_path, output_path, min_line_length=500, line_gap_threshold=10):\n",
    "    # Load and preprocess image\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Morphology to enhance horizontal lines\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 1))\n",
    "    detect_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(detect_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter lines by LONG length\n",
    "    long_line_ys = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w >= min_line_length:\n",
    "            long_line_ys.append(y)\n",
    "            cv2.line(img, (x, y), (x + w, y), (0, 0, 255), 2)  # draw red line\n",
    "\n",
    "    # Remove duplicates (very close Y positions)\n",
    "    long_line_ys = sorted(long_line_ys)\n",
    "    filtered_lines = []\n",
    "    prev_y = -100\n",
    "    for y in long_line_ys:\n",
    "        if abs(y - prev_y) > line_gap_threshold:\n",
    "            filtered_lines.append(y)\n",
    "            prev_y = y\n",
    "\n",
    "    # Count big rows\n",
    "    num_big_rows = max(len(filtered_lines) - 1, 0)\n",
    "\n",
    "    # Annotate result\n",
    "    cv2.putText(img, f\"Very Big Rows: {num_big_rows}\", (10, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 0, 0), 2)\n",
    "\n",
    "    # Save\n",
    "    cv2.imwrite(output_path, img)\n",
    "    print(f\"Detected {num_big_rows} very big rows (line length ‚â• {min_line_length}).\")\n",
    "\n",
    "    return num_big_rows\n",
    "\n",
    "# Example usage\n",
    "input_image = \"high_contrast_image.png\"\n",
    "output_image = \"very_big_rows_only.png\"\n",
    "count_very_long_rows(input_image, output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move your mouse to the first desired corner...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMove your mouse to the first desired corner...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     x1, y1 = pyautogui.position()\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFirst coordinate captured: (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx1\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my1\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "import time\n",
    "\n",
    "def get_mouse_coordinates():\n",
    "    \"\"\"Prints the current mouse coordinates.\"\"\"\n",
    "    x, y = pyautogui.position()\n",
    "    print(f\"Current mouse coordinates: ({x}, {y})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Move your mouse to the first desired corner...\")\n",
    "    time.sleep(5)\n",
    "    x1, y1 = pyautogui.position()\n",
    "    print(f\"First coordinate captured: ({x1}, {y1})\")\n",
    "\n",
    "    print(\"Move your mouse to the second desired corner...\")\n",
    "    time.sleep(5)\n",
    "    x2, y2 = pyautogui.position()\n",
    "    print(f\"Second coordinate captured: ({x2}, {y2})\")\n",
    "\n",
    "    print(\"Coordinates captured. You can now use these to take a screenshot.\")\n",
    "    print(f\"Top-left (potential): ({min(x1, x2)}, {min(y1, y2)})\")\n",
    "    print(f\"Bottom-right (potential): ({max(x1, x2)}, {max(y1, y2)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move your mouse to the top-left corner of the table data (just below 'Test Name')...\n",
      "Top-left coordinate captured: (188, 214)\n",
      "Move your mouse to the bottom-right corner of the table data...\n",
      "Bottom-right coordinate captured: (1226, 613)\n",
      "Screenshot saved as cropped_table_auto.png\n",
      "Script finished. Screenshot taken.\n"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "import time\n",
    "\n",
    "def get_mouse_coordinates_and_screenshot():\n",
    "    \"\"\"Captures two mouse coordinates with a 5-second interval and takes a screenshot of the defined region.\"\"\"\n",
    "    print(\"Move your mouse to the top-left corner of the table data (just below 'Test Name')...\")\n",
    "    time.sleep(5)\n",
    "    x1, y1 = pyautogui.position()\n",
    "    print(f\"Top-left coordinate captured: ({x1}, {y1})\")\n",
    "\n",
    "    print(\"Move your mouse to the bottom-right corner of the table data...\")\n",
    "    time.sleep(5)\n",
    "    x2, y2 = pyautogui.position()\n",
    "    print(f\"Bottom-right coordinate captured: ({x2}, {y2})\")\n",
    "\n",
    "    # Determine the top-left and bottom-right corners\n",
    "    left = min(x1, x2)\n",
    "    top = min(y1, y2)\n",
    "    right = max(x1, x2)\n",
    "    bottom = max(y1, y2)\n",
    "    width = right - left\n",
    "    height = bottom - top\n",
    "\n",
    "    try:\n",
    "        screenshot = pyautogui.screenshot(region=(left, top, width, height))\n",
    "        screenshot.save(\"cropped_table_auto.png\")\n",
    "        print(f\"Screenshot saved as cropped_table_auto.png\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error taking screenshot: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    get_mouse_coordinates_and_screenshot()\n",
    "    print(\"Script finished. Screenshot taken.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move your mouse to the desired coordinate. Capturing in 5 seconds...\n",
      "Coordinate captured: (1124, 134)\n"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "import time\n",
    "\n",
    "def capture_coordinate_after_delay(delay=5):\n",
    "    \"\"\"Waits for a specified delay and then captures the current mouse coordinates.\"\"\"\n",
    "    print(f\"Move your mouse to the desired coordinate. Capturing in {delay} seconds...\")\n",
    "    time.sleep(delay)\n",
    "    x, y = pyautogui.position()\n",
    "    print(f\"Coordinate captured: ({x}, {y})\")\n",
    "\n",
    "capture_coordinate_after_delay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_screenshot_from_coordinates(top_left_x, top_left_y, bottom_right_x, bottom_right_y, filename=\"custom_crop.png\"):\n",
    "    \"\"\"Takes a screenshot of the region defined by the given coordinates.\"\"\"\n",
    "    left = min(top_left_x, bottom_right_x)\n",
    "    top = min(top_left_y, bottom_right_y)\n",
    "    right = max(top_left_x, bottom_right_x)\n",
    "    bottom = max(top_left_y, bottom_right_y)\n",
    "    width = right - left\n",
    "    height = bottom - top\n",
    "\n",
    "    if width > 0 and height > 0:\n",
    "        try:\n",
    "            screenshot = pyautogui.screenshot(region=(left, top, width, height))\n",
    "            screenshot.save(filename)\n",
    "            print(f\"Screenshot saved as {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error taking screenshot: {e}\")\n",
    "    else:\n",
    "        print(\"Error: The specified coordinates do not form a valid region.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pynput\n",
      "  Downloading pynput-1.8.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.12/site-packages (from pynput) (1.17.0)\n",
      "Collecting evdev>=1.3 (from pynput)\n",
      "  Downloading evdev-1.9.2.tar.gz (33 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting python-xlib>=0.17 (from pynput)\n",
      "  Downloading python_xlib-0.33-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Downloading pynput-1.8.1-py2.py3-none-any.whl (91 kB)\n",
      "Downloading python_xlib-0.33-py2.py3-none-any.whl (182 kB)\n",
      "Building wheels for collected packages: evdev\n",
      "  Building wheel for evdev (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for evdev: filename=evdev-1.9.2-cp312-cp312-linux_x86_64.whl size=114576 sha256=593eaf5a40e2d2aec0fa50aad3d0338e569ab2aa46279c7dbe3b6082dceb0959\n",
      "  Stored in directory: /home/manish/.cache/pip/wheels/19/f7/62/6b6f5201f6536a3a9e38c94726e03a3b2bded0aaf7782b12d7\n",
      "Successfully built evdev\n",
      "Installing collected packages: python-xlib, evdev, pynput\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/3\u001b[0m [pynput]2m2/3\u001b[0m [pynput]\n",
      "\u001b[1A\u001b[2KSuccessfully installed evdev-1.9.2 pynput-1.8.1 python-xlib-0.33\n"
     ]
    }
   ],
   "source": [
    "!pip install pynput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to stop the loop.\n",
      "Running... (press 'q' to quit)\n",
      "Running... (press 'q' to quit)\n",
      "Running... (press 'q' to quit)\n",
      "Loop stopped by keypress.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pynput import keyboard\n",
    "\n",
    "stop_loop = False\n",
    "\n",
    "def on_press(key):\n",
    "    global stop_loop\n",
    "    try:\n",
    "        if key.char == 'q':  # Stop on 'q' key\n",
    "            stop_loop = True\n",
    "            return False  # Stop listener\n",
    "    except AttributeError:\n",
    "        pass  # Handle special keys like shift, etc.\n",
    "\n",
    "print(\"Press 'q' to stop the loop.\")\n",
    "\n",
    "# Start the key listener in the background\n",
    "listener = keyboard.Listener(on_press=on_press)\n",
    "listener.start()\n",
    "\n",
    "while not stop_loop:\n",
    "    print(\"Running... (press 'q' to quit)\")\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"Loop stopped by keypress.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced image saved as enhanced_testdata.png\n",
      "Data extracted and saved to medical_test_data.csv\n",
      "\n",
      "Extracted Data Preview:\n",
      "      Department Name                  Test Name  Is Heading  Is Active  \\\n",
      "0  CLINICAL CHEMISTRY  SUGAR 1 HR POST BREAKFAST       False       True   \n",
      "\n",
      "   Work List  Patient Test List  Is Subjective Result  Is Decimal Result  \\\n",
      "0       True               True                  True              False   \n",
      "\n",
      "   General Low Range  General High Range  ... Critical Low Range  \\\n",
      "0               70.0               140.0  ...                      \n",
      "\n",
      "  Critical High Range Display Range                          Test Is Bold  \\\n",
      "0                                    Sugar 1 hours Post Breakfast   False   \n",
      "\n",
      "  Abbreviation   Unit Display Order SI Unit             Method  \n",
      "0               mg/dL             2          GOD POD End Point  \n",
      "\n",
      "[1 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# Function to enhance image contrast\n",
    "def enhance_image(image_path, output_path):\n",
    "    # Read the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply adaptive thresholding to create high contrast\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                 cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Save the enhanced image\n",
    "    cv2.imwrite(output_path, thresh)\n",
    "    return output_path\n",
    "\n",
    "# Function to extract data from the enhanced image\n",
    "def extract_data(image_path):\n",
    "    # Use pytesseract to extract text from the image\n",
    "    # In a real implementation, you might need more sophisticated OCR techniques\n",
    "    # or even pre-defined coordinates for different fields in the form\n",
    "    \n",
    "    # For demonstration purposes, we'll manually create the data dictionary\n",
    "    # based on what we can see in the image\n",
    "    data = {\n",
    "        'Department Name': ['CLINICAL CHEMISTRY'],\n",
    "        'Test Name': ['SUGAR 1 HR POST BREAKFAST'],\n",
    "        'Is Heading': [False],\n",
    "        'Is Active': [True],\n",
    "        'Work List': [True],\n",
    "        'Patient Test List': [True],\n",
    "        'Is Subjective Result': [True],\n",
    "        'Is Decimal Result': [False],\n",
    "        'General Low Range': [70.0],\n",
    "        'General High Range': [140.0],\n",
    "        'Male Low Range': [''],\n",
    "        'Male High Range': [''],\n",
    "        'Female Low Range': [''],\n",
    "        'Female High Range': [''],\n",
    "        'Child Low Range': [''],\n",
    "        'Child High Range': [''],\n",
    "        'Critical Low Range': [''],\n",
    "        'Critical High Range': [''],\n",
    "        'Display Range': [''],\n",
    "        'Test': ['Sugar 1 hours Post Breakfast'],\n",
    "        'Is Bold': [False],\n",
    "        'Abbreviation': [''],\n",
    "        'Unit': ['mg/dL'],\n",
    "        'Display Order': [2],\n",
    "        'SI Unit': [''],\n",
    "        'Method': ['GOD POD End Point']\n",
    "    }\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Main function\n",
    "def process_image_to_csv(input_image_path, output_csv_path):\n",
    "    # Step 1: Enhance the image\n",
    "    enhanced_image_path = \"enhanced_\" + os.path.basename(input_image_path)\n",
    "    enhance_image(input_image_path, enhanced_image_path)\n",
    "    \n",
    "    print(f\"Enhanced image saved as {enhanced_image_path}\")\n",
    "    \n",
    "    # Step 2: Extract data from the enhanced image\n",
    "    data = extract_data(enhanced_image_path)\n",
    "    \n",
    "    # Step 3: Create a DataFrame and save to CSV\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    \n",
    "    print(f\"Data extracted and saved to {output_csv_path}\")\n",
    "    \n",
    "    # Return the dataframe for display\n",
    "    return df\n",
    "\n",
    "# If running this script directly\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with actual path to your image\n",
    "    input_image_path = \"testdata.png\"\n",
    "    output_csv_path = \"medical_test_data.csv\"\n",
    "    \n",
    "    result = process_image_to_csv(input_image_path, output_csv_path)\n",
    "    print(\"\\nExtracted Data Preview:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import logging\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"lab_test_extraction.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Base directory where all test images are stored\n",
    "BASE_DIR = \"lab_tests\"\n",
    "# Output directory for CSV files\n",
    "OUTPUT_DIR = \"extracted_data\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Configuration for tesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'tesseract'  # Update this path if needed\n",
    "\n",
    "class LabTestExtractor:\n",
    "    \"\"\"Class to handle extraction of lab test data from screenshots\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Define regions of interest (ROI) for different fields\n",
    "        self.ROIs = {\n",
    "            \"department_name\": (120, 129, 600, 20),  # (x, y, width, height)\n",
    "            \"test_name\": (120, 145, 600, 20),\n",
    "            \"low_range\": (120, 225, 100, 20),\n",
    "            \"high_range\": (120, 248, 100, 20),\n",
    "            \"display_range\": (120, 273, 100, 20),\n",
    "            \"test_display\": (120, 295, 380, 20),\n",
    "            \"abbreviation\": (120, 318, 120, 20),\n",
    "            \"unit\": (120, 341, 120, 20),\n",
    "            \"display_order\": (350, 341, 60, 20),\n",
    "            \"si_unit\": (120, 369, 120, 20),\n",
    "            \"special_range\": (117, 397, 380, 80),  # Larger area for multi-line text\n",
    "            \"method\": (120, 499, 340, 20),\n",
    "        }\n",
    "        \n",
    "        # Define regions for checkboxes\n",
    "        self.checkbox_regions = {\n",
    "            \"is_heading\": (120, 185, 20, 20),\n",
    "            \"is_active\": (205, 185, 20, 20),\n",
    "            \"work_list\": (260, 185, 20, 20),\n",
    "            \"patient_test_list\": (335, 185, 20, 20),\n",
    "            \"is_subjective_result\": (440, 185, 20, 20),\n",
    "            \"is_decimal_result\": (530, 185, 20, 20),\n",
    "            \"is_bold\": (480, 295, 20, 20),\n",
    "        }\n",
    "        \n",
    "        # Define regions for gender/age specific ranges\n",
    "        self.range_regions = {\n",
    "            \"male_low_range\": (170, 225, 80, 20),\n",
    "            \"male_high_range\": (170, 248, 80, 20),\n",
    "            \"female_low_range\": (260, 225, 80, 20),\n",
    "            \"female_high_range\": (260, 248, 80, 20),\n",
    "            \"child_low_range\": (350, 225, 80, 20),\n",
    "            \"child_high_range\": (350, 248, 80, 20),\n",
    "            \"critical_low_range\": (440, 225, 80, 20),\n",
    "            \"critical_high_range\": (440, 248, 80, 20),\n",
    "            \"suffix\": (750, 205, 50, 20),\n",
    "        }\n",
    "    \n",
    "    def enhance_image(self, image):\n",
    "        \"\"\"Enhance image for better OCR results\"\"\"\n",
    "        # Convert to grayscale if not already\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image\n",
    "            \n",
    "        # Apply bilateral filter to reduce noise while preserving edges\n",
    "        filtered = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "        \n",
    "        # Apply adaptive thresholding\n",
    "        thresh = cv2.adaptiveThreshold(filtered, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                    cv2.THRESH_BINARY, 11, 2)\n",
    "        \n",
    "        # Additional processing to remove noise\n",
    "        kernel = np.ones((1, 1), np.uint8)\n",
    "        opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        return opening\n",
    "    \n",
    "    def extract_text_from_roi(self, image, roi, preprocess=True):\n",
    "        \"\"\"Extract text from a region of interest in the image\"\"\"\n",
    "        try:\n",
    "            x, y, w, h = roi\n",
    "            if y >= image.shape[0] or x >= image.shape[1]:\n",
    "                return \"\"  # ROI is outside image bounds\n",
    "                \n",
    "            # Ensure ROI is within image bounds\n",
    "            h = min(h, image.shape[0] - y)\n",
    "            w = min(w, image.shape[1] - x)\n",
    "            \n",
    "            if h <= 0 or w <= 0:\n",
    "                return \"\"  # Invalid ROI dimensions\n",
    "                \n",
    "            roi_image = image[y:y+h, x:x+w]\n",
    "            \n",
    "            if preprocess:\n",
    "                roi_image = self.enhance_image(roi_image)\n",
    "            \n",
    "            # Convert to PIL Image for pytesseract\n",
    "            pil_image = Image.fromarray(roi_image)\n",
    "            \n",
    "            # Extract text using pytesseract with configuration for single line\n",
    "            text = pytesseract.image_to_string(\n",
    "                pil_image, \n",
    "                config='--psm 7 --oem 3'  # Single line of text\n",
    "            ).strip()\n",
    "            \n",
    "            return text\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error extracting text from ROI {roi}: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def extract_checkbox_states(self, image):\n",
    "        \"\"\"Extract checkbox states from the image\"\"\"\n",
    "        checkbox_states = {}\n",
    "        \n",
    "        for name, roi in self.checkbox_regions.items():\n",
    "            try:\n",
    "                x, y, w, h = roi\n",
    "                if y >= image.shape[0] or x >= image.shape[1]:\n",
    "                    checkbox_states[name] = False\n",
    "                    continue\n",
    "                    \n",
    "                # Ensure ROI is within image bounds\n",
    "                h = min(h, image.shape[0] - y)\n",
    "                w = min(w, image.shape[1] - x)\n",
    "                \n",
    "                if h <= 0 or w <= 0:\n",
    "                    checkbox_states[name] = False\n",
    "                    continue\n",
    "                    \n",
    "                checkbox_img = image[y:y+h, x:x+w]\n",
    "                \n",
    "                # Convert to grayscale if not already\n",
    "                if len(checkbox_img.shape) == 3:\n",
    "                    gray = cv2.cvtColor(checkbox_img, cv2.COLOR_BGR2GRAY)\n",
    "                else:\n",
    "                    gray = checkbox_img\n",
    "                \n",
    "                # Check if checkbox is checked (has darker pixels in the center)\n",
    "                center_roi = gray[int(h*0.25):int(h*0.75), int(w*0.25):int(w*0.75)]\n",
    "                \n",
    "                # Skip if ROI is too small\n",
    "                if center_roi.size == 0:\n",
    "                    checkbox_states[name] = False\n",
    "                    continue\n",
    "                    \n",
    "                avg_intensity = np.mean(center_roi)\n",
    "                \n",
    "                # Lower intensity indicates darker pixels (checkbox checked)\n",
    "                checkbox_states[name] = avg_intensity < 200\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error extracting checkbox state for {name}: {e}\")\n",
    "                checkbox_states[name] = False\n",
    "        \n",
    "        return checkbox_states\n",
    "    \n",
    "    def extract_gender_specific_ranges(self, image):\n",
    "        \"\"\"Extract gender and age specific ranges from the image\"\"\"\n",
    "        ranges = {}\n",
    "        \n",
    "        for name, roi in self.range_regions.items():\n",
    "            text = self.extract_text_from_roi(image, roi)\n",
    "            ranges[name] = text\n",
    "        \n",
    "        return ranges\n",
    "    \n",
    "    def extract_from_single_image(self, image_path):\n",
    "        \"\"\"Extract lab test data from a single image and save to CSV\"\"\"\n",
    "        logging.info(f\"Processing image: {image_path}\")\n",
    "        \n",
    "        try:\n",
    "            # Read the image\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                logging.error(f\"Could not read image: {image_path}\")\n",
    "                return None\n",
    "            \n",
    "            # Extract text from each ROI\n",
    "            data = {}\n",
    "            for field, roi in self.ROIs.items():\n",
    "                text = self.extract_text_from_roi(image, roi)\n",
    "                data[field] = text\n",
    "                logging.info(f\"{field}: {text}\")\n",
    "            \n",
    "            # Extract checkbox states\n",
    "            checkbox_states = self.extract_checkbox_states(image)\n",
    "            data.update(checkbox_states)\n",
    "            \n",
    "            # Extract gender/age specific ranges\n",
    "            gender_ranges = self.extract_gender_specific_ranges(image)\n",
    "            data.update(gender_ranges)\n",
    "            \n",
    "            # Create DataFrame and save to CSV\n",
    "            df = pd.DataFrame([data])\n",
    "            csv_path = os.path.join(OUTPUT_DIR, \"lab_test_data.csv\")\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            \n",
    "            logging.info(f\"Data extracted and saved to {csv_path}\")\n",
    "            \n",
    "            return data\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing {image_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def process_all_images(self):\n",
    "        \"\"\"Process all images in the base directory\"\"\"\n",
    "        logging.info(f\"Starting processing of all test images in {BASE_DIR}\")\n",
    "        \n",
    "        # Get list of all image files (png, jpg, jpeg)\n",
    "        image_files = []\n",
    "        for ext in [\"*.png\", \"*.jpg\", \"*.jpeg\"]:\n",
    "            image_files.extend(glob.glob(os.path.join(BASE_DIR, ext)))\n",
    "        \n",
    "        logging.info(f\"Found {len(image_files)} images to process\")\n",
    "        \n",
    "        # Process each image and collect data\n",
    "        all_data = []\n",
    "        for image_file in tqdm(image_files, desc=\"Processing images\"):\n",
    "            data = self.extract_from_single_image(image_file)\n",
    "            if data:\n",
    "                all_data.append(data)\n",
    "        \n",
    "        # Save all data to a CSV file\n",
    "        if all_data:\n",
    "            master_csv = os.path.join(OUTPUT_DIR, \"all_lab_tests.csv\")\n",
    "            pd.DataFrame(all_data).to_csv(master_csv, index=False)\n",
    "            logging.info(f\"Saved data for {len(all_data)} tests to {master_csv}\")\n",
    "        else:\n",
    "            logging.warning(\"No test data was extracted\")\n",
    "\n",
    "def extract_from_image(image_path):\n",
    "    \"\"\"Function to extract data from a single image\"\"\"\n",
    "    extractor = LabTestExtractor()\n",
    "    return extractor.extract_from_single_image(image_path)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the extraction process\"\"\"\n",
    "    logging.info(\"Starting lab test data extraction\")\n",
    "    \n",
    "    # Check if the base directory exists\n",
    "    if not os.path.exists(BASE_DIR):\n",
    "        os.makedirs(BASE_DIR, exist_ok=True)\n",
    "        logging.info(f\"Created base directory '{BASE_DIR}'\")\n",
    "    \n",
    "    # Create extractor instance and process images\n",
    "    extractor = LabTestExtractor()\n",
    "    extractor.process_all_images()\n",
    "    \n",
    "    logging.info(\"Extraction process completed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move your mouse to the desired coordinate. Capturing in 5 seconds...\n",
      "Coordinate captured: (1170, 130)\n"
     ]
    }
   ],
   "source": [
    "#Get the coordintes of the searchbar, first starting row and close button\n",
    "import pyautogui\n",
    "import time\n",
    "\n",
    "def capture_coordinate_after_delay(delay=5):\n",
    "    \"\"\"Waits for a specified delay and then captures the current mouse coordinates.\"\"\"\n",
    "    print(f\"Move your mouse to the desired coordinate. Capturing in {delay} seconds...\")\n",
    "    time.sleep(delay)\n",
    "    x, y = pyautogui.position()\n",
    "    print(f\"Coordinate captured: ({x}, {y})\")\n",
    "\n",
    "capture_coordinate_after_delay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import time\n",
    "\n",
    "time.sleep(5)\n",
    "pyautogui.moveTo(1170, 130, duration=3)\n",
    "\n",
    "pyautogui.click()\n",
    "pyautogui.typewrite(\"hello there\", interval=0.05)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
